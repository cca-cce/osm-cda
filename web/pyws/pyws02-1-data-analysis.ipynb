{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"dataframe manipulation\"\n",
        "---\n",
        "\n",
        "- dataframe examples [pandas](https://pandas.pydata.org/docs/user_guide/index.html){target=\"_blank\"}\n",
        "- dataframe examples [polars](https://docs.pola.rs/){target=\"_blank\"}\n",
        "- download [jupyter notebook](pyws02-1-data-analysis.ipynb)\n",
        "\n",
        "## read and explore data\n",
        "\n",
        "Here is an analysis of your code, separated into logical steps with each step in its own code chunk, followed by explanations:\n",
        "\n",
        "### 1. Import necessary libraries\n",
        "\n",
        "```python\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "```\n",
        "\n",
        "**Explanation:**  \n",
        "This step imports the required libraries for the script. `seaborn` is a data visualization library that provides built-in datasets, and `pandas` is used for data manipulation and analysis. Importing these libraries allows the script to use their functions, such as loading a dataset and manipulating DataFrames.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Load the dataset and select specific columns\n",
        "\n",
        "```python\n",
        "df = sns.load_dataset(\"penguins\")\n",
        "df_selected = df[['body_mass_g', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'island']]\n",
        "```\n",
        "\n",
        "**Explanation:**  \n",
        "Here, the `penguins` dataset from Seaborn is loaded into a Pandas DataFrame (`df`). The next step selects specific columns of interest (`body_mass_g`, `bill_length_mm`, `bill_depth_mm`, `flipper_length_mm`, and `island`) and stores them in `df_selected`. These columns represent both the dependent and independent variables used for further analysis.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Rename selected columns for easier reference\n",
        "\n",
        "```python\n",
        "df_renamed = df_selected.rename(columns={\n",
        "    'body_mass_g': 'dep_var', \n",
        "    'bill_length_mm': 'indep_var_1', \n",
        "    'bill_depth_mm': 'indep_var_2', \n",
        "    'flipper_length_mm': 'indep_var_3', \n",
        "    'island': 'indep_var_4'\n",
        "})\n",
        "```\n",
        "\n",
        "**Explanation:**  \n",
        "This step renames the columns of `df_selected` to more generic names for easier reference. The dependent variable (`body_mass_g`) is renamed to `dep_var`, and the independent variables are renamed to `indep_var_1`, `indep_var_2`, `indep_var_3`, and `indep_var_4` (for `island`). This renamed DataFrame (`df_renamed`) is used for subsequent analysis.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Save the renamed DataFrame as a TSV file\n",
        "\n",
        "```python\n",
        "output_file_path = '/home/sol-nhl/rnd/d/quarto/osm-cda/csv/data.tsv'\n",
        "df_renamed.to_csv(output_file_path, sep='\\t', index=False)\n",
        "```\n",
        "\n",
        "**Explanation:**  \n",
        "The renamed DataFrame is saved to a TSV (tab-separated values) file at the specified path. The `to_csv()` method is used with the `sep='\\t'` argument to ensure that the file is saved in TSV format. The `index=False` option prevents the DataFrame index from being written to the file.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Generate summary statistics of the DataFrame\n",
        "\n",
        "```python\n",
        "summary_stats = df_renamed.describe()\n",
        "```\n",
        "\n",
        "**Explanation:**  \n",
        "This step generates summary statistics for all numeric columns in the DataFrame using the `describe()` function. The resulting DataFrame (`summary_stats`) contains descriptive statistics such as count, mean, standard deviation, minimum, and maximum values, as well as the quartile ranges for the selected variables.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. Retrieve the first five records of the DataFrame\n",
        "\n",
        "```python\n",
        "first_five_records = df_renamed.head()\n",
        "```\n",
        "\n",
        "**Explanation:**  \n",
        "The `head()` function retrieves the first five rows of the DataFrame. This is useful for a quick inspection of the dataset to verify that the data was loaded and renamed correctly. The `first_five_records` DataFrame contains the first five records of the renamed DataFrame.\n",
        "\n",
        "---\n",
        "\n",
        "### 7. Convert a column to a categorical data type\n",
        "\n",
        "```python\n",
        "df_renamed['indep_var_4'] = df_renamed['indep_var_4'].astype('category')\n",
        "```\n",
        "\n",
        "**Explanation:**  \n",
        "This step converts the `indep_var_4` column (formerly `island`) to a categorical data type using `astype('category')`. Categorical data types are more memory efficient and appropriate when dealing with a limited number of distinct values, such as categorical variables in a dataset.\n",
        "\n",
        "---\n",
        "\n",
        "### 8. Fill missing values in numeric columns with their mean\n",
        "\n",
        "```python\n",
        "df_filled = df_renamed.fillna(df_renamed.mean(numeric_only=True))\n",
        "```\n",
        "\n",
        "**Explanation:**  \n",
        "In this step, any missing values in the numeric columns of `df_renamed` are filled with the mean value of each column using `fillna()`. The `mean(numeric_only=True)` calculates the mean for only numeric columns, and `fillna()` replaces the missing values with these means. The modified DataFrame is stored as `df_filled`.\n",
        "\n",
        "---\n",
        "\n",
        "### 9. Remove rows with any remaining missing values\n",
        "\n",
        "```python\n",
        "df_no_missing = df_filled.dropna()\n",
        "```\n",
        "\n",
        "**Explanation:**  \n",
        "Here, the `dropna()` function is used to remove any rows that still contain missing values in the DataFrame after filling the numeric columns. Rows with missing values in non-numeric columns will be dropped. The cleaned DataFrame is stored as `df_no_missing`.\n",
        "\n",
        "---\n",
        "\n",
        "### 10. Remove duplicate records\n",
        "\n",
        "```python\n",
        "df_no_duplicates = df_no_missing.drop_duplicates()\n",
        "```\n",
        "\n",
        "**Explanation:**  \n",
        "This step removes any duplicate rows from the DataFrame using the `drop_duplicates()` method. Duplicate rows are those where all column values are identical. The resulting DataFrame (`df_no_duplicates`) contains only unique rows, ensuring there are no duplicate records in the dataset.\n",
        "\n",
        "---\n",
        "\n",
        "### 11. Output summary statistics and first five records\n",
        "\n",
        "```python\n",
        "print(summary_stats)\n",
        "print(first_five_records)\n",
        "```\n",
        "\n",
        "**Explanation:**  \n",
        "The final step prints the summary statistics generated earlier (`summary_stats`) and the first five records (`first_five_records`) of the renamed DataFrame. This provides an overview of the dataset and allows verification that the data processing steps were applied correctly.\n",
        "\n",
        "\n",
        "\n",
        "Here's the Python code to perform the requested data analysis steps without execution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import necessary libraries\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load data into a DataFrame called df\n",
        "df = sns.load_dataset(\"penguins\")\n",
        "\n",
        "# Selecting a dependent variable (e.g., body_mass_g) and a few independent variables\n",
        "# Renaming them as per the requirement\n",
        "df_selected = df[['body_mass_g', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'island']]\n",
        "\n",
        "# Renaming columns for easier reference\n",
        "df_renamed = df_selected.rename(columns={\n",
        "  'body_mass_g': 'dep_var', \n",
        "  'bill_length_mm': 'indep_var_1', \n",
        "  'bill_depth_mm': 'indep_var_2', \n",
        "  'flipper_length_mm': 'indep_var_3', \n",
        "  'island': 'indep_var_4'\n",
        "})\n",
        "\n",
        "# Step 2: Save the DataFrame as a TSV file\n",
        "output_file_path = '/home/sol-nhl/rnd/d/quarto/osm-cda/csv/data.tsv'\n",
        "df_renamed.to_csv(output_file_path, sep='\\t', index=False)\n",
        "\n",
        "# Step 3: Summary statistics of the DataFrame\n",
        "summary_stats = df_renamed.describe()\n",
        "\n",
        "# Step 4: Retrieving the first five records\n",
        "first_five_records = df_renamed.head()\n",
        "\n",
        "# Step 5: Changing column types (for example, converting 'indep_var_4' to a categorical variable)\n",
        "df_renamed['indep_var_4'] = df_renamed['indep_var_4'].astype('category')\n",
        "\n",
        "# Step 6: Filling missing values (filling numeric columns with their mean values)\n",
        "df_filled = df_renamed.fillna(df_renamed.mean(numeric_only=True))\n",
        "\n",
        "# Step 7: Removing missing values (dropping rows with any remaining missing values)\n",
        "df_no_missing = df_filled.dropna()\n",
        "\n",
        "# Step 8: Removing duplicate records\n",
        "df_no_duplicates = df_no_missing.drop_duplicates()\n",
        "\n",
        "# Output result to verify (summary statistics and first five records)\n",
        "print(summary_stats)\n",
        "print(first_five_records)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### load and clean, summary\n",
        "1. **Loading Data**: The `penguins` dataset from seaborn is loaded into a DataFrame called `df`.\n",
        "2. **Saving Data as TSV**: The cleaned DataFrame (`df_renamed`) is saved as a TSV file to the specified path.\n",
        "3. **Summary Statistics**: The `describe()` method is used to calculate summary statistics for the DataFrame.\n",
        "4. **First Five Records**: The first five records are retrieved using the `head()` method.\n",
        "5. **Renaming Columns**: Columns are renamed for easier reference, changing variable names like `body_mass_g` to `dep_var` and others to `indep_var_1`, `indep_var_2`, and so on.\n",
        "6. **Changing Column Types**: The `indep_var_4` column (originally `island`) is converted to a categorical data type.\n",
        "7. **Filling Missing Values**: Missing values in numeric columns are filled using the mean of each column.\n",
        "8. **Removing Missing Values**: Rows with any remaining missing values are dropped.\n",
        "9. **Removing Duplicates**: Duplicate records in the DataFrame are removed.\n",
        "\n",
        "This code prepares and cleans the dataset for further analysis, ensuring that missing and duplicate values are handled and the DataFrame is saved as a `.tsv` file.\n",
        "\n",
        "## select and group data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load df from the TSV file (input_file_path)\n",
        "input_file_path = '/home/sol-nhl/rnd/d/quarto/osm-cda/csv/data.tsv'\n",
        "df = pd.read_csv(input_file_path, sep='\\t')\n",
        "\n",
        "# Step 2: Filtering data (example: filter rows where dep_var > 3500)\n",
        "filtered_df = df[df['dep_var'] > 3500]\n",
        "\n",
        "# Step 3: Selecting the required columns (example: selecting dep_var and indep_var_1)\n",
        "selected_columns = filtered_df[['dep_var', 'indep_var_1', 'indep_var_4']]\n",
        "\n",
        "# Step 4: Grouping data example (example: group by indep_var_4 and calculate mean dep_var)\n",
        "grouped_data = df.groupby('indep_var_4')['dep_var'].mean().reset_index()\n",
        "\n",
        "# Step 5: Merging data with another DataFrame (example: merging original df with grouped_data on indep_var_4)\n",
        "merged_df = pd.merge(df, grouped_data, on='indep_var_4', suffixes=('', '_mean'))\n",
        "\n",
        "# Step 6: Calculating a new column (example: calculate the difference between dep_var and dep_var_mean)\n",
        "merged_df['dep_var_diff'] = merged_df['dep_var'] - merged_df['dep_var_mean']\n",
        "\n",
        "# Step 7: Creating a Pivot table (example: pivot table with indep_var_4 as index and dep_var as values, mean of dep_var)\n",
        "pivot_table = merged_df.pivot_table(values='dep_var', index='indep_var_4', aggfunc='mean')\n",
        "\n",
        "# Step 8: Save the Pivot table as a TSV file\n",
        "output_file_path = '/home/sol-nhl/rnd/d/quarto/osm-cda/csv/data_pivot.tsv'\n",
        "pivot_table.to_csv(output_file_path, sep='\\t')\n",
        "\n",
        "# Output result to verify (filtered data, selected columns, grouped data, merged data, and pivot table)\n",
        "print(filtered_df.head())\n",
        "print(selected_columns.head())\n",
        "print(grouped_data.head())\n",
        "print(merged_df.head())\n",
        "print(pivot_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### select and group, summary\n",
        "1. **Loading Data**: The TSV file located at `/home/sol-nhl/rnd/d/quarto/osm-cda/csv/data.tsv` is loaded into a DataFrame called `df` using `pd.read_csv()` with tab-separated values.\n",
        "\n",
        "2. **Filtering Data**: An example filter is applied to select rows where the dependent variable (`dep_var`) is greater than 3500.\n",
        "\n",
        "3. **Selecting Columns**: The relevant columns are selected, including the dependent variable (`dep_var`), one of the independent variables (`indep_var_1`), and the grouping variable (`indep_var_4`).\n",
        "\n",
        "4. **Grouping Data**: The data is grouped by the independent variable (`indep_var_4`) and the mean of `dep_var` is calculated for each group.\n",
        "\n",
        "5. **Merging Data**: The original DataFrame (`df`) is merged with the grouped data (mean `dep_var` for each `indep_var_4`) on the `indep_var_4` column.\n",
        "\n",
        "6. **Calculating a New Column**: A new column (`dep_var_diff`) is calculated as the difference between each penguin's `dep_var` and the group mean `dep_var`.\n",
        "\n",
        "7. **Creating a Pivot Table**: A pivot table is generated, showing the mean `dep_var` for each category in `indep_var_4`.\n",
        "\n",
        "8. **Saving the Data**: The resulting pivot table is saved to a new TSV file at `/home/sol-nhl/rnd/d/quarto/osm-cda/csv/data_pivot.tsv`.\n",
        "\n",
        "This code accomplishes the task of analyzing the **penguins** dataset by filtering, selecting, grouping, merging, calculating a new column, creating a pivot table, and saving the final output to a TSV file.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/usr/local/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}