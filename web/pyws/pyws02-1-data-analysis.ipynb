{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"dataframe manipulation\"\n",
        "---\n",
        "\n",
        "- dataframe examples [pandas](https://pandas.pydata.org/docs/user_guide/index.html){target=\"_blank\"}\n",
        "- dataframe examples [polars](https://docs.pola.rs/){target=\"_blank\"}\n",
        "- download [jupyter notebook](pyws02-1-data-analysis.ipynb)\n",
        "\n",
        "## read and explore data\n",
        "\n",
        "Here is an analysis of your code, separated into logical steps with each step in its own code chunk, followed by explanations:\n",
        "\n",
        "### 1. Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "This step imports the required libraries for the script. `seaborn` is a data visualization library that provides built-in datasets, and `pandas` is used for data manipulation and analysis. Importing these libraries allows the script to use their functions, such as loading a dataset and manipulating DataFrames.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Load the dataset and select specific columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = sns.load_dataset(\"penguins\")\n",
        "df_selected = df[['body_mass_g', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'island']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "Here, the `penguins` dataset from Seaborn is loaded into a Pandas DataFrame (`df`). The next step selects specific columns of interest (`body_mass_g`, `bill_length_mm`, `bill_depth_mm`, `flipper_length_mm`, and `island`) and stores them in `df_selected`. These columns represent both the dependent and independent variables used for further analysis.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Rename selected columns for easier reference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_renamed = df_selected.rename(columns={\n",
        "    'body_mass_g': 'dep_var', \n",
        "    'bill_length_mm': 'indep_var_1', \n",
        "    'bill_depth_mm': 'indep_var_2', \n",
        "    'flipper_length_mm': 'indep_var_3', \n",
        "    'island': 'indep_var_4'\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "This step renames the columns of `df_selected` to more generic names for easier reference. The dependent variable (`body_mass_g`) is renamed to `dep_var`, and the independent variables are renamed to `indep_var_1`, `indep_var_2`, `indep_var_3`, and `indep_var_4` (for `island`). This renamed DataFrame (`df_renamed`) is used for subsequent analysis.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Save the renamed DataFrame as a TSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "output_file_path = '/home/sol-nhl/rnd/d/quarto/osm-cda/csv/data.tsv'\n",
        "df_renamed.to_csv(output_file_path, sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "The renamed DataFrame is saved to a TSV (tab-separated values) file at the specified path. The `to_csv()` method is used with the `sep='\\t'` argument to ensure that the file is saved in TSV format. The `index=False` option prevents the DataFrame index from being written to the file.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Generate summary statistics of the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "summary_stats = df_renamed.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "This step generates summary statistics for all numeric columns in the DataFrame using the `describe()` function. The resulting DataFrame (`summary_stats`) contains descriptive statistics such as count, mean, standard deviation, minimum, and maximum values, as well as the quartile ranges for the selected variables.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. Retrieve the first five records of the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "first_five_records = df_renamed.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "The `head()` function retrieves the first five rows of the DataFrame. This is useful for a quick inspection of the dataset to verify that the data was loaded and renamed correctly. The `first_five_records` DataFrame contains the first five records of the renamed DataFrame.\n",
        "\n",
        "---\n",
        "\n",
        "### 7. Convert a column to a categorical data type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_renamed['indep_var_4'] = df_renamed['indep_var_4'].astype('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "This step converts the `indep_var_4` column (formerly `island`) to a categorical data type using `astype('category')`. Categorical data types are more memory efficient and appropriate when dealing with a limited number of distinct values, such as categorical variables in a dataset.\n",
        "\n",
        "---\n",
        "\n",
        "### 8. Fill missing values in numeric columns with their mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_filled = df_renamed.fillna(df_renamed.mean(numeric_only=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "In this step, any missing values in the numeric columns of `df_renamed` are filled with the mean value of each column using `fillna()`. The `mean(numeric_only=True)` calculates the mean for only numeric columns, and `fillna()` replaces the missing values with these means. The modified DataFrame is stored as `df_filled`.\n",
        "\n",
        "---\n",
        "\n",
        "### 9. Remove rows with any remaining missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_no_missing = df_filled.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "Here, the `dropna()` function is used to remove any rows that still contain missing values in the DataFrame after filling the numeric columns. Rows with missing values in non-numeric columns will be dropped. The cleaned DataFrame is stored as `df_no_missing`.\n",
        "\n",
        "---\n",
        "\n",
        "### 10. Remove duplicate records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_no_duplicates = df_no_missing.drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "This step removes any duplicate rows from the DataFrame using the `drop_duplicates()` method. Duplicate rows are those where all column values are identical. The resulting DataFrame (`df_no_duplicates`) contains only unique rows, ensuring there are no duplicate records in the dataset.\n",
        "\n",
        "---\n",
        "\n",
        "### 11. Output summary statistics and first five records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(summary_stats)\n",
        "print(first_five_records)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "The final step prints the summary statistics generated earlier (`summary_stats`) and the first five records (`first_five_records`) of the renamed DataFrame. This provides an overview of the dataset and allows verification that the data processing steps were applied correctly.\n",
        "\n",
        "## select and group data\n",
        "\n",
        "Here is an analysis of your Python code, separated into logical steps with each step in its own code chunk, followed by explanations:\n",
        "\n",
        "### 1. Import the necessary library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "This line imports the Pandas library, a powerful Python tool for data manipulation and analysis. By importing Pandas, the script gains access to functions like reading data, filtering, grouping, and saving results.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Load DataFrame from TSV File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "input_file_path = '/home/sol-nhl/rnd/d/quarto/osm-cda/csv/data.tsv'\n",
        "df = pd.read_csv(input_file_path, sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "This block reads a TSV (tab-separated values) file from the specified file path (`input_file_path`) into a Pandas DataFrame (`df`). The `sep='\\t'` argument specifies that the file uses tabs as delimiters. The result is a DataFrame containing the data from the TSV file, with columns and rows ready for further manipulation.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Filter the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "filtered_df = df[df['dep_var'] > 3500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "Here, the DataFrame is filtered to include only rows where the value in the `dep_var` column is greater than `3500`. The resulting filtered DataFrame (`filtered_df`) contains a subset of the original data that meets this condition.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Select Specific Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "selected_columns = filtered_df[['dep_var', 'indep_var_1', 'indep_var_4']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "In this step, a new DataFrame (`selected_columns`) is created by selecting only the specified columns (`dep_var`, `indep_var_1`, and `indep_var_4`) from the previously filtered DataFrame. This reduces the dataset to just the relevant columns needed for further analysis.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Group Data and Calculate the Mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grouped_data = df.groupby('indep_var_4')['dep_var'].mean().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "This block groups the data by the `indep_var_4` column and calculates the mean of the `dep_var` column for each group. The result is stored in `grouped_data`, a DataFrame containing the unique values of `indep_var_4` and their corresponding mean `dep_var` values. The `reset_index()` function ensures the grouped values are converted back into a DataFrame format.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. Merge DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "merged_df = pd.merge(df, grouped_data, on='indep_var_4', suffixes=('', '_mean'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "This step merges the original DataFrame (`df`) with the `grouped_data` DataFrame on the `indep_var_4` column. The result (`merged_df`) contains all original columns from `df` along with the mean `dep_var` for each group. The `suffixes=('', '_mean')` ensures that the new `dep_var_mean` column has a distinct name.\n",
        "\n",
        "---\n",
        "\n",
        "### 7. Calculate a New Column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "merged_df['dep_var_diff'] = merged_df['dep_var'] - merged_df['dep_var_mean']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "A new column (`dep_var_diff`) is added to the `merged_df` DataFrame. This column represents the difference between the original `dep_var` values and the mean `dep_var` values for each group (from the merged `dep_var_mean` column). The result provides insight into how each `dep_var` deviates from the group mean.\n",
        "\n",
        "---\n",
        "\n",
        "### 8. Create a Pivot Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pivot_table = merged_df.pivot_table(values='dep_var', index='indep_var_4', aggfunc='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "This block creates a pivot table from `merged_df`, where `indep_var_4` becomes the index, and the mean of `dep_var` is calculated for each value of `indep_var_4`. The result is stored in the `pivot_table` DataFrame, which aggregates the data by `indep_var_4` and provides a summary of the mean `dep_var`.\n",
        "\n",
        "---\n",
        "\n",
        "### 9. Save the Pivot Table as a TSV File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "output_file_path = '/home/sol-nhl/rnd/d/quarto/osm-cda/csv/data_pivot.tsv'\n",
        "pivot_table.to_csv(output_file_path, sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "In this step, the `pivot_table` DataFrame is saved as a TSV file to the specified path (`output_file_path`). The `sep='\\t'` argument ensures that the data is saved in tab-separated format. This allows the pivot table to be stored and used for further analysis or reporting.\n",
        "\n",
        "---\n",
        "\n",
        "### 10. Output Results to Verify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(filtered_df.head())\n",
        "print(selected_columns.head())\n",
        "print(grouped_data.head())\n",
        "print(merged_df.head())\n",
        "print(pivot_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:**  \n",
        "This final block prints the first few rows (`head()`) of various DataFrames, including the filtered data, selected columns, grouped data, merged data, and the pivot table. These print statements allow you to verify the results of each step in the analysis.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/usr/local/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}